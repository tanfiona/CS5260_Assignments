{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HptO0CSwNjie"
      },
      "source": [
        "# Assignment 5 -- Contrastive Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkIokoYtNI_G"
      },
      "source": [
        "Please submit this file to Luminus by **23:59 on 20 Mar**. \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. Finish 2 tasks according to the instructions. Only change the code in the required area and DO NOT change others or add new code/text snippets.\n",
        "2. Rename this file as \"Student_number.ipynb\". e.g., 'A0000000J.ipynb'. \n",
        "\n",
        "3. Submit the file to /Files/assignments/submission/assignment5. \n",
        "\n",
        "Please follow the instructions strictly, otherwise you might be penalized.\n",
        "\n",
        "If you has any questions, please propose it on Slack, or contact Ziheng Qin (e0823059@u.nus.edu) and Yong Liu (e0672130@u.nus.edu)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXC8nEmxOMN6"
      },
      "source": [
        "First, we import the dataset and define transformation operations on it. We apply random transformation on images (crop + flip + colorjitter + grayscale)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hIWaDsVYG4OH"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "\n",
        "class CIFAR10Pair(CIFAR10):\n",
        "    \"\"\"CIFAR10 Dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            pos_1 = self.transform(img)\n",
        "            pos_2 = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return pos_1, pos_2, target\n",
        "\n",
        "# preprocess dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct01fnfSNHuT"
      },
      "source": [
        "We use commonly used ResNet-50 as ConvNet encoders for simplicity in the original paper. The task 1 is to set encoder and projection head. The parameters are adapted from the original paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZbjYxzrgG6rO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models.resnet import resnet50\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, feature_dim=128):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.f = []\n",
        "        for name, module in resnet50().named_children():\n",
        "            if name == 'conv1':\n",
        "                module = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "            if not isinstance(module, nn.Linear) and not isinstance(module, nn.MaxPool2d):\n",
        "                self.f.append(module)\n",
        "        # ----------------------------------------------------------------------\n",
        "        # START OF YOUR CODE\n",
        "        # ----------------------------------------------------------------------\n",
        "        # Task 1\n",
        "        # set a neural network base encoder self.f\n",
        "        # hint: nn.Sequential\n",
        "\n",
        "        self.f = nn.Sequential(*self.f)\n",
        "\n",
        "        # set a small neural network projection head\n",
        "        # Dense-> Relu-> Dense (2-layer MLP to project the representation to a 128-dimensional latent space and \n",
        "        # the representation is 2048-dimensional here)\n",
        "        \n",
        "        self.g = nn.Sequential(\n",
        "            nn.Linear(2048, 512), # Hidden dim decided to be 512 but can be any number\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, feature_dim)\n",
        "        )\n",
        "        # ----------------------------------------------------------------------\n",
        "        # END OF YOUR CODE\n",
        "        # ----------------------------------------------------------------------\n",
        "    def forward(self, x):\n",
        "        x = self.f(x)\n",
        "        feature = torch.flatten(x, start_dim=1)\n",
        "        out = self.g(feature)\n",
        "        return F.normalize(feature, dim=-1), F.normalize(out, dim=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPM5hsulQ74i"
      },
      "source": [
        "We train encoder network and projection head to maximize agreement using a contrastive loss. The default epoch is 1 for time efficiency while it could takes about 10 minutes to run for one epoch in google colab. The task 2 is to calculate the contrastive loss.\n",
        "To evaluate the influence of temperature value for contrastive loss, we run this training process 3 times with different temperature value (0.1,0.5 and 1.0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7FrLDw2HAWN",
        "outputId": "b28d192b-4d01-46be-8aad-af0d133f90e1",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (0.0.31.post2005241907)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from thop) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->thop) (3.10.0.2)\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "!pip install thop\n",
        "from thop import profile, clever_format\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "def contrastive_loss(out_1, out_2, temperature):\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # START OF YOUR CODE\n",
        "    # ------------------------------------------------------------------\n",
        "    # Task2: implement contrastive loss function and return loss variable\n",
        "    # hint: loss formula could refer to the slides\n",
        "    # input: out_1, out_2ï¼Œtemperature\n",
        "    # output: loss variable\n",
        "\n",
        "    # out_1 and out_2 each has dimensions of B x dim_z\n",
        "    # B: batch size\n",
        "    \n",
        "    # Get similarity score matrix, the grid in Slide 38: 2B x 2B\n",
        "    out = torch.cat([out_1, out_2], dim=0).cuda()\n",
        "    numer = torch.matmul(out, out.t()).cuda()\n",
        "    denom = temperature * torch.norm(out).cuda() * torch.norm(out).cuda()\n",
        "    sim_score = (numer/denom).cuda()\n",
        "\n",
        "    # Remove items when k=i, the diagonals: 2B x (2B-1)\n",
        "    mask = (torch.ones_like(sim_score) - torch.eye(2*batch_size, device=sim_score.device)).bool()\n",
        "    sim_score = sim_score.masked_select(mask).view(2*batch_size, -1)\n",
        "\n",
        "    # Calculate loss formula in Slide 47\n",
        "    denom = sim_score.sum(dim=-1).cuda() # 2B\n",
        "    numer = torch.exp(torch.sum(out_1*out_2, dim=-1)/temperature).cuda() # B\n",
        "    numer = torch.cat([numer,numer],dim=0).cuda() # 2B\n",
        "    loss = -torch.log(numer/denom).mean() # Mean \n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # END OF YOUR CODE\n",
        "    # ------------------------------------------------------------------\n",
        "\n",
        "    return loss\n",
        "\n",
        "# train for one epoch to learn unique features\n",
        "def train(net, data_loader, train_optimizer, temperature):\n",
        "    net.train()\n",
        "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)\n",
        "    for pos_1, pos_2, target in train_bar:\n",
        "        pos_1, pos_2 = pos_1.cuda(non_blocking=True), pos_2.cuda(non_blocking=True)\n",
        "        feature_1, out_1 = net(pos_1)\n",
        "        feature_2, out_2 = net(pos_2)\n",
        "\n",
        "        loss = contrastive_loss(out_1, out_2, temperature)\n",
        "\n",
        "        train_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_optimizer.step()\n",
        "\n",
        "        total_num += batch_size\n",
        "        total_loss += loss.item() * batch_size\n",
        "        train_bar.set_description('Train Epoch: [{}/{}] Loss: {:.4f}'.format(epoch, epochs, total_loss / total_num))\n",
        "\n",
        "    return total_loss / total_num\n",
        "\n",
        "\n",
        "# test for one epoch, use weighted knn to find the most similar images' label to assign the test image\n",
        "def test(net, memory_data_loader, test_data_loader, temperature):\n",
        "    net.eval()\n",
        "    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n",
        "    with torch.no_grad():\n",
        "        # generate feature bank\n",
        "        for data, _, target in tqdm(memory_data_loader, desc='Feature extracting'):\n",
        "            feature, out = net(data.cuda(non_blocking=True))\n",
        "            feature_bank.append(feature)\n",
        "        # [D, N]\n",
        "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
        "        # [N]\n",
        "        feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\n",
        "        # loop test data to predict the label by weighted knn search\n",
        "        test_bar = tqdm(test_data_loader)\n",
        "        for data, _, target in test_bar:\n",
        "            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n",
        "            feature, out = net(data)\n",
        "\n",
        "            total_num += data.size(0)\n",
        "            # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
        "            sim_matrix = torch.mm(feature, feature_bank)\n",
        "            # [B, K]\n",
        "            sim_weight, sim_indices = sim_matrix.topk(k=k, dim=-1)\n",
        "            # [B, K]\n",
        "            sim_labels = torch.gather(feature_labels.expand(data.size(0), -1), dim=-1, index=sim_indices)\n",
        "            sim_weight = (sim_weight / temperature).exp()\n",
        "\n",
        "            # counts for each class\n",
        "            one_hot_label = torch.zeros(data.size(0) * k, c, device=sim_labels.device)\n",
        "            # [B*K, C]\n",
        "            one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
        "            # weighted score ---> [B, C]\n",
        "            pred_scores = torch.sum(one_hot_label.view(data.size(0), -1, c) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
        "\n",
        "            pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
        "            total_top1 += torch.sum((pred_labels[:, :1] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
        "            total_top5 += torch.sum((pred_labels[:, :5] == target.unsqueeze(dim=-1)).any(dim=-1).float()).item()\n",
        "            test_bar.set_description('Test Epoch: [{}/{}] Acc@1:{:.2f}% Acc@5:{:.2f}%'\n",
        "                                     .format(epoch, epochs, total_top1 / total_num * 100, total_top5 / total_num * 100))\n",
        "\n",
        "    return total_top1 / total_num * 100, total_top5 / total_num * 100\n",
        "\n",
        "# Train SimCLR\n",
        "   \n",
        "# Feature dim for latent vector, Temperature used in softmax, Top k most similar images used to predict the label\n",
        "feature_dim, temp, k = 128, [0.1, 0.5, 1], 200\n",
        "# Number of images in each mini-batch, Number of sweeps over the dataset to train\n",
        "batch_size, epochs = 128, 1\n",
        "# data prepare\n",
        "train_data = CIFAR10Pair(root='data', train=True, transform=train_transform, download=True)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True,drop_last=True)\n",
        "memory_data = CIFAR10Pair(root='data', train=True, transform=test_transform, download=True)\n",
        "memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
        "test_data = CIFAR10Pair(root='data', train=False, transform=test_transform, download=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDI2uLbQWgjf",
        "outputId": "861dae19-cbc3-4209-deed-29d27cf79da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/thop/vision/basic_hooks.py:92: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  kernel = torch.DoubleTensor([*(x[0].shape[2:])]) // torch.DoubleTensor(list((m.output_size,))).squeeze()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.resnet.Bottleneck'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.Model'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "# Model Params: 24.62M FLOPs: 1.31G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/390 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Train Epoch: [1/1] Loss: -7.6989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 390/390 [13:24<00:00,  2.06s/it]\n",
            "Feature extracting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [02:11<00:00,  2.98it/s]\n",
            "Test Epoch: [1/1] Acc@1:29.31% Acc@5:79.89%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:29<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.resnet.Bottleneck'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.Model'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "# Model Params: 24.62M FLOPs: 1.31G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: [1/1] Loss: -1.3105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 390/390 [13:23<00:00,  2.06s/it]\n",
            "Feature extracting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [02:11<00:00,  2.98it/s]\n",
            "Test Epoch: [1/1] Acc@1:29.01% Acc@5:80.01%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:29<00:00,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "\u001b[91m[WARN] Cannot find rule for <class 'torchvision.models.resnet.Bottleneck'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "\u001b[91m[WARN] Cannot find rule for <class '__main__.Model'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
            "# Model Params: 24.62M FLOPs: 1.31G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: [1/1] Loss: nan: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 390/390 [13:26<00:00,  2.07s/it]\n",
            "Feature extracting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 391/391 [02:11<00:00,  2.97it/s]\n",
            "Test Epoch: [1/1] Acc@1:20.30% Acc@5:67.66%: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:30<00:00,  2.63it/s]\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "\n",
        "for i in range(len(temp)):\n",
        "\n",
        "    # model setup and optimizer config\n",
        "    model = Model(feature_dim).cuda()\n",
        "    flops, params = profile(model, inputs=(torch.randn(1, 3, 32, 32).cuda(),))\n",
        "    flops, params = clever_format([flops, params])\n",
        "    print('# Model Params: {} FLOPs: {}'.format(params, flops))\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
        "    c = len(memory_data.classes)\n",
        "\n",
        "    results = {'train_loss': [], 'test_acc@1': [], 'test_acc@5': []}\n",
        "    save_name_pre = '{}_{}_{}_{}_{}'.format(feature_dim, temp[i], k, batch_size, epochs)\n",
        "    if not os.path.exists('results'):\n",
        "        os.mkdir('results')\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, train_loader, optimizer, temp[i])\n",
        "        results['train_loss'].append(train_loss)\n",
        "        test_acc_1, test_acc_5 = test(model, memory_loader, test_loader, temp[i])\n",
        "        results['test_acc@1'].append(test_acc_1)\n",
        "        results['test_acc@5'].append(test_acc_5)\n",
        "        # save statistics\n",
        "        data_frame = pd.DataFrame(data=results, index=range(1, epoch + 1))\n",
        "        data_frame.to_csv('results/{}_statistics.csv'.format(save_name_pre), index_label='epoch')\n",
        "        if test_acc_1 > best_acc:\n",
        "            best_acc = test_acc_1\n",
        "            torch.save(model.state_dict(), 'results/{}_model.pth'.format(save_name_pre))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ContrastiveLearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}